{"version": 2, "status": "success", "eval": {"eval_id": "Gy9caVoeMDNwhSJ4kXc4dg", "run_id": "eBJr9BLZwzpkcDeT4CgLNf", "created": "2025-08-05T03:22:47+00:00", "task": "openbench/musr", "task_id": "FccSjFxChau3xNjq9SredH", "task_version": 0, "task_registry_name": "openbench/musr", "task_attribs": {}, "task_args": {"subset": "murder_mysteries"}, "task_args_passed": {}, "dataset": {"name": "TAUR-Lab/MuSR", "location": "TAUR-Lab/MuSR", "samples": 250, "sample_ids": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "shuffled": false}, "model": "openrouter/openai/gpt-4.1-nano", "model_generate_config": {"timeout": 10000, "max_connections": 10, "top_p": 1.0, "temperature": 0.6}, "model_base_url": "https://openrouter.ai/api/v1", "model_args": {}, "model_roles": {"grader_model": {"model": "openrouter/openai/gpt-4.1-mini", "config": {}, "base_url": "https://openrouter.ai/api/v1", "args": {}}}, "config": {"limit": 10, "epochs": 1, "epochs_reducer": ["mean"], "fail_on_error": true, "sandbox_cleanup": true, "log_samples": true, "log_realtime": true, "log_images": true, "log_buffer": 10, "score_display": true}, "revision": {"type": "git", "origin": "https://github.com/christopherwoodall/ci-model-test", "commit": "bb303c6"}, "packages": {"inspect_ai": "0.3.115"}, "scorers": [{"name": "choice", "options": {}, "metrics": [{"name": "inspect_ai/accuracy", "options": {}}, {"name": "inspect_ai/stderr", "options": {}}], "metadata": {}}]}, "plan": {"name": "plan", "steps": [{"solver": "multiple_choice", "params": {}}], "config": {"timeout": 10000, "max_connections": 10, "top_p": 1.0, "temperature": 0.6}}, "results": {"total_samples": 10, "completed_samples": 10, "scores": [{"name": "choice", "scorer": "choice", "scored_samples": 10, "unscored_samples": 0, "params": {}, "metrics": {"accuracy": {"name": "accuracy", "value": 0.7, "params": {}}, "stderr": {"name": "stderr", "value": 0.15275252316519464, "params": {}}}}]}, "stats": {"started_at": "2025-08-05T03:22:47+00:00", "completed_at": "2025-08-05T03:22:48+00:00", "model_usage": {"openrouter/openai/gpt-4.1-nano": {"input_tokens": 11821, "output_tokens": 30, "total_tokens": 11851, "input_tokens_cache_read": 0, "reasoning_tokens": 0}}}}