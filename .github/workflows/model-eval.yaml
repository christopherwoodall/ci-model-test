name: Model Evaluation CI/CD

on:
  schedule:
    - cron: '0 0 * * *' # Runs daily at midnight UTC (1 PM PDT)
  workflow_dispatch:      # Allows manual triggering

jobs:
  evaluate-models:
    runs-on: ubuntu-latest

    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.head_ref }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run model evaluation
        id: eval
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        run: |
            python evaluation.py --config config.yaml            
            echo "push=true" >> $GITHUB_OUTPUT

      - name: Generate report
        run: |
          python report_generator.py

      - name: Push changes
        if: steps.eval.outputs.push == 'true'
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

          if git status --porcelain | grep -q '\.json$'; then
            git add *.json
            git commit -m "Automated: Add model evaluation results"
            git push
          else
            echo "No new files to commit."
          fi

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./docs
